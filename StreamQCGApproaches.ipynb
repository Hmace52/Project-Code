{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Required installs/imports\n"
      ],
      "metadata": {
        "id": "gEtAF1ghdNj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pure-prng"
      ],
      "metadata": {
        "id": "t3QeVxqDH5qP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a5ff164-d900-4c0f-ad3b-b87ae162efbd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pure-prng\n",
            "  Downloading pure_prng-2.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting pure-nrng>=1.1.0\n",
            "  Downloading pure_nrng-1.1.0-py3-none-any.whl (21 kB)\n",
            "Collecting gmpy2>=2.0.8\n",
            "  Downloading gmpy2-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting randomgen>=1.20.3\n",
            "  Downloading randomgen-1.23.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from randomgen>=1.20.3->pure-prng) (1.22.4)\n",
            "Installing collected packages: gmpy2, randomgen, pure-nrng, pure-prng\n",
            "Successfully installed gmpy2-2.1.5 pure-nrng-1.1.0 pure-prng-2.9.0 randomgen-1.23.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RvbBxhpgt7Ig"
      },
      "outputs": [],
      "source": [
        "# Necessary imports\n",
        "from pure_prng_package import pure_prng\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes to provide data generation/evaluation methods"
      ],
      "metadata": {
        "id": "T0n19N9-dRnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class used to access my implmentations of PRNGs\n",
        "class PRNGManagement():\n",
        "  # Initialises object and sets the default seed\n",
        "  def __init__(self, seed=0):\n",
        "      self.seed = seed\n",
        "      self.random_number:int = seed\n",
        "      self.currentGenerator = self.zero_only_PRNG()\n",
        "\n",
        "  # Method to seed the PRNG (seeds all PRNGs in class)\n",
        "  def seed_PRNG(self, seed:int):\n",
        "    self.seed:int = seed\n",
        "    self.random_number:int = seed\n",
        "\n",
        "  def set_generator(self, generatorMethod):\n",
        "    self.currentGenerator = generatorMethod\n",
        "\n",
        "  def bit_success(self, model, inputData, trueOutputs, sequence_length):\n",
        "    \"\"\" \n",
        "    Method to evaluate the provided model and store the amount of\n",
        "    successful predictions for each bit of the output\n",
        "    :param model: keras model - Model used to generate predicitions\n",
        "    :param trueOutputs: list[list[int]]- List containing the expected y outputs\n",
        "    :param sequence_length: int - Length of generated binary string being predicited\n",
        "    :return list[int] - Amount of successful predictions for each bit\n",
        "    \"\"\"\n",
        "    # Set initial amount of successful predictions for each bit to zero\n",
        "    successfulPredicts = [0]*sequence_length\n",
        "    # Feeds the input data to the model and stores the predictions made\n",
        "    predicted = (model.predict(inputData).round())\n",
        "    # Iterate over all outputed data\n",
        "    for testIndex in range(0, len(inputData)):\n",
        "      # Iterate over each bit in output\n",
        "      for i in range(sequence_length):\n",
        "        # If the predicted bit matches the true bit value then increment the successful predicts for the current bit\n",
        "        if predicted[testIndex][i] == trueOutputs[testIndex][i]: successfulPredicts[i] += 1\n",
        "        # Prediction may be greater than 1 if the prediction is made with high certainity\n",
        "        elif predicted[testIndex][i] > 1 and trueOutputs[testIndex][i] == 1: self.successfulPredicts[i] += 1\n",
        "\n",
        "    return successfulPredicts\n",
        "   \n",
        "\n",
        "  def zero_only_PRNG(self, length=100):\n",
        "    \"\"\" \n",
        "    Returns a binary string containing only 0 of specified length.\n",
        "    Used to test for major flaws in models\n",
        "    :param length: int - Length of generated binary string\n",
        "    :return string - generated binary string\n",
        "    \"\"\"\n",
        "    return \"0\" * length        \n",
        "\n",
        "\n",
        "  def alternating_bits_PRNG(self, length=100):\n",
        "    \"\"\" \n",
        "    Returns output of a basic PRNG implementation that alernates each bit (010101)\n",
        "    :param length: int - Length of generated binary string\n",
        "    :return string - generated binary string\n",
        "    \"\"\"\n",
        "    # Use seed to determine the starting bit of the generated binary string\n",
        "    self.seed = self.seed%2\n",
        "    # Utilises efficent method to repeat a string pattern\n",
        "    if (self.seed == 1):\n",
        "        output = \"10\" * int(length/2)\n",
        "    else:\n",
        "        output = \"01\" * int(length/2)\n",
        "\n",
        "    # Length of generated binary string is odd\n",
        "    if (length%2 == 1):\n",
        "      # Add final bit to string\n",
        "      output += str(self.seed)\n",
        "      # Set the new seed value\n",
        "      if (self.seed == 0): self.seed = 1\n",
        "      else: self.seed = 0\n",
        "    \n",
        "    return output\n",
        "\n",
        "\n",
        "  def alternating_num_PRNG(self):\n",
        "    \"\"\" \n",
        "    Returns output of a basic PRNG implementation that alernates between two binary strings\n",
        "    :return string - generated binary string\n",
        "    \"\"\"\n",
        "    # Use seed to determine the binary string to be returned\n",
        "    self.seed = (self.seed+1)%2\n",
        "    if (self.seed == 0):\n",
        "      # Convert integer to a binary string \n",
        "      randomBinary = str(bin(1643712566))[2:]\n",
        "      # Returns binary string after ensuring a minimum length of 32\n",
        "      return (32-len(randomBinary))*\"0\" + randomBinary\n",
        "    else:\n",
        "      # Convert integer to a binary string \n",
        "      randomBinary = str(bin(2372817037))[2:]\n",
        "      # Returns binary string after ensuring a minimum length of 32\n",
        "      return (32-len(randomBinary))*\"0\" + randomBinary\n",
        "\n",
        "\n",
        "  def basic_equation_based(self, mult:int, add:int, mod:int, leng:int) -> str:\n",
        "    \"\"\" \n",
        "    Returns output of a very weak equation based PRNG implementation\n",
        "    Expected to be predicted near perfectly\n",
        "    :return string - generated binary string\n",
        "    \"\"\"\n",
        "    # Generates random number using previous output as seed\n",
        "    self.random_number = (mult * self.random_number + add) % mod\n",
        "    # Converts generated number to a binary string\n",
        "    bits_string = bin(self.random_number)[2:]\n",
        "    # Returns binary string after using padding to ensure a length of 32\n",
        "    return bits_string.zfill(leng)\n",
        "\n",
        "\n",
        "  ## Different implmentations of equation based generators\n",
        "  def basic_equation_based1(self) -> str:\n",
        "    return self.basic_equation_based(20, 52, 2**32, 32)\n",
        "\n",
        "  def basic_equation_based2(self) -> str:\n",
        "    return self.basic_equation_based(36791, 83247, 2**32, 32)\n",
        "\n",
        "  # Expects odd starting seed\n",
        "  # Imeplementation of the PRNG 'RANDU' - Outdated PRNG\n",
        "  def RANDU(self) -> str:\n",
        "    return self.basic_equation_based(65539, 0, 2**31, 31)\n",
        "\n",
        "  # Implementation of the Park Miller PRNG - Outdated PRNG\n",
        "  def Park_Miller(self) -> str:\n",
        "    return self.basic_equation_based(16807, 0, 2**31-1, 32)\n",
        "\n",
        "  # Get stream of binary data form current generator\n",
        "  def get_stream(self, number_of_blocks:int):\n",
        "    stream = []\n",
        "    for _ in range(number_of_blocks):\n",
        "      # Converts generated binary string to list of ints\n",
        "      block = [int(bit) for bit in self.currentGenerator()] \n",
        "      stream.extend(block)\n",
        "    return stream"
      ],
      "metadata": {
        "id": "5XBLpCikQu5X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class used to manage the PRNGs offered by the PRNG library\n",
        "class PRNGLibManagement():\n",
        "  def __init__(self, PRNGType:str, outputLen:int):\n",
        "    self.change_PRNG(PRNGType, outputLen)\n",
        "\n",
        "  # Change the type of the current PRNG\n",
        "  def change_PRNG(self, PRNGType:str, outputLen:int):\n",
        "    self.outputLen = outputLen\n",
        "    self.PRNGType = PRNGType\n",
        "    self.currentGen = pure_prng(int(time.time()), prng_type=PRNGType).source_random_number()\n",
        "\n",
        "  # Seed the current PRNG\n",
        "  def seed_current(self, seed=int(time.time())):\n",
        "    self.currentGen = pure_prng(int(seed), prng_type=self.PRNGType).source_random_number()\n",
        "\n",
        "  # Generates an output from the curent PRNG\n",
        "  def output_current(self):\n",
        "    # Converts generated number to a binary string\n",
        "    bits_string = bin(next(self.currentGen))[2:]\n",
        "    # Returns binary string after using padding to ensure a consistent length\n",
        "    return bits_string.zfill(self.outputLen)\n",
        "\n",
        "  # Generates output from current PRNG as a list containing the integer bits\n",
        "  def next_ints(self):\n",
        "    # Converts generated binary string to list of ints\n",
        "    return [int(bit) for bit in self.output_current()] \n",
        "\n",
        "  # Get stream of binary data form current generator\n",
        "  def get_stream(self, number_of_blocks:int):\n",
        "    stream = []\n",
        "    for _ in range(number_of_blocks):\n",
        "      block = self.next_ints()\n",
        "      stream.extend(block)\n",
        "    return stream"
      ],
      "metadata": {
        "id": "-GBuWcChUelq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data generation function to be used during data production"
      ],
      "metadata": {
        "id": "dgeMdcbIdvIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates object to use the 'QCG' PRNG\n",
        "PRNGLibHandler = PRNGLibManagement(\"QCG\", 256)\n",
        "\n",
        "# Generation/seed functions for use\n",
        "def generatorOutput(blockNum): return PRNGLibHandler.get_stream(blockNum)\n",
        "def seedGenerator(seed): PRNGLibHandler.seed_current(seed)"
      ],
      "metadata": {
        "id": "LGELTqwOVa9h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting parameters for data generation"
      ],
      "metadata": {
        "id": "et5qzmMCfX1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Setting parameters\n",
        "# Sets paramemters for generating train/test data\n",
        "num_blocks = 500\n",
        "sequence_length = 256\n",
        "\n",
        "# Calculates number of samples produced\n",
        "num_samples = (num_blocks-1)*sequence_length\n",
        "\n",
        "print(\"Number of samples: \", num_samples)"
      ],
      "metadata": {
        "id": "3KJKALf4fYvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5bd8789-7808-4dd0-fd2e-26c9c4edfdce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  127744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Produces data for training/testing"
      ],
      "metadata": {
        "id": "-Df9x0k625Pt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "L-H_--JU6MG7"
      },
      "outputs": [],
      "source": [
        "# Seed generator\n",
        "seedGenerator(23)\n",
        "# Get stream data \n",
        "streamData = generatorOutput(num_blocks)\n",
        "\n",
        "# Stores output in variable to allow the sample to be featued in both x and y data\n",
        "X_data, Y_data = [], []\n",
        "\n",
        "# Extracts stream data samples\n",
        "for i in range(num_samples):\n",
        "  X_data.append(streamData[i:i+sequence_length])\n",
        "  Y_data.append([streamData[i+sequence_length]])\n",
        "\n",
        "# Deletes stream data to save memory\n",
        "del streamData"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting data into training/testing sets"
      ],
      "metadata": {
        "id": "iq9MmfLU27Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Separate data into training/testing sets\n",
        "# Percentage of data used for testing the created prediction model\n",
        "testDataPerc = 0.2\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_data, Y_data, test_size = testDataPerc, random_state = 5)\n",
        "\n",
        "del X_data\n",
        "del Y_data"
      ],
      "metadata": {
        "id": "BkYDUqe1Eg9X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creation and training of different models"
      ],
      "metadata": {
        "id": "bLBDBWwdjFqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dense + Normalisation + Dropout"
      ],
      "metadata": {
        "id": "Uq1tec2ljHMh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx3kGN-5tXFp",
        "outputId": "22decb63-9717-4523-ef6a-2212efe1d0aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,377\n",
            "Trainable params: 100,097\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Sets parameters for model\n",
        "epochs = 10\n",
        "\n",
        "# Strategy to utilise GPU \n",
        "strategy = tf.distribute.OneDeviceStrategy('/gpu:0')\n",
        "\n",
        "# Model compilation using GPU\n",
        "with strategy.scope():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(sequence_length, input_shape=(sequence_length, ), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(rate=0.2))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(sequence_length//2, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr4ICgfxAVur",
        "outputId": "4b80fade-e8ca-4b3c-9a79-dad66aa20a14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1022/1022 [==============================] - 36s 28ms/step - loss: 0.7165 - accuracy: 0.5003 - val_loss: 0.6964 - val_accuracy: 0.5030\n",
            "Epoch 2/10\n",
            "1022/1022 [==============================] - 7s 7ms/step - loss: 0.6919 - accuracy: 0.5241 - val_loss: 0.6960 - val_accuracy: 0.5026\n",
            "Epoch 3/10\n",
            "1022/1022 [==============================] - 6s 6ms/step - loss: 0.6900 - accuracy: 0.5350 - val_loss: 0.6985 - val_accuracy: 0.4975\n",
            "Epoch 4/10\n",
            "1022/1022 [==============================] - 6s 6ms/step - loss: 0.6873 - accuracy: 0.5431 - val_loss: 0.7018 - val_accuracy: 0.4988\n",
            "Epoch 5/10\n",
            "1022/1022 [==============================] - 8s 8ms/step - loss: 0.6849 - accuracy: 0.5500 - val_loss: 0.7004 - val_accuracy: 0.5032\n",
            "Epoch 6/10\n",
            "1022/1022 [==============================] - 7s 7ms/step - loss: 0.6814 - accuracy: 0.5625 - val_loss: 0.7068 - val_accuracy: 0.4994\n",
            "Epoch 7/10\n",
            "1022/1022 [==============================] - 7s 6ms/step - loss: 0.6765 - accuracy: 0.5740 - val_loss: 0.7110 - val_accuracy: 0.4950\n",
            "Epoch 8/10\n",
            "1022/1022 [==============================] - 7s 7ms/step - loss: 0.6718 - accuracy: 0.5843 - val_loss: 0.7140 - val_accuracy: 0.4978\n",
            "Epoch 9/10\n",
            "1022/1022 [==============================] - 7s 7ms/step - loss: 0.6666 - accuracy: 0.5923 - val_loss: 0.7174 - val_accuracy: 0.5004\n",
            "Epoch 10/10\n",
            "1022/1022 [==============================] - 7s 6ms/step - loss: 0.6630 - accuracy: 0.5991 - val_loss: 0.7217 - val_accuracy: 0.4992\n"
          ]
        }
      ],
      "source": [
        "batch_size = 100\n",
        "# Train the model with the x/y train data and validate using the test data after each epoch\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"QCGDND1.h5\")"
      ],
      "metadata": {
        "id": "HcbluaPBhC3r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Long Short-Term Memory"
      ],
      "metadata": {
        "id": "ZXK--YgNjLKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets parameters for model\n",
        "epochs = 10\n",
        "\n",
        "# Strategy to utilise GPU \n",
        "strategy = tf.distribute.OneDeviceStrategy('/gpu:0')\n",
        "\n",
        "# Model compilation using GPU\n",
        "with strategy.scope():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(int(sequence_length), input_shape=(sequence_length, 1), return_sequences=True))\n",
        "  model.add(LSTM(int(sequence_length/1.5), return_sequences=True))\n",
        "  model.add(LSTM(int(sequence_length/2)))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
        "\n",
        "  model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTPCqRdDFb54",
        "outputId": "084707f1-ce5b-4f41-de5b-7609bd2d6a09"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 256, 256)          264192    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 256, 170)          290360    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 128)               153088    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 707,769\n",
            "Trainable params: 707,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "# Train the model with the x/y train data and validate using the test data after each epoch\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "7cKOcRUWt64y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f377591-242b-4d8b-a5a7-428397fd5392"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1022/1022 [==============================] - 104s 95ms/step - loss: 0.6933 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.5003\n",
            "Epoch 2/10\n",
            "1022/1022 [==============================] - 76s 74ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5027\n",
            "Epoch 3/10\n",
            "1022/1022 [==============================] - 75s 74ms/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6933 - val_accuracy: 0.5006\n",
            "Epoch 4/10\n",
            "1022/1022 [==============================] - 75s 73ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5006\n",
            "Epoch 5/10\n",
            "1022/1022 [==============================] - 76s 75ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6932 - val_accuracy: 0.5006\n",
            "Epoch 6/10\n",
            "1022/1022 [==============================] - 76s 74ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.4994\n",
            "Epoch 7/10\n",
            "1022/1022 [==============================] - 76s 74ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6931 - val_accuracy: 0.4994\n",
            "Epoch 8/10\n",
            "1022/1022 [==============================] - 76s 74ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.4994\n",
            "Epoch 9/10\n",
            "1022/1022 [==============================] - 78s 77ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5006\n",
            "Epoch 10/10\n",
            "1022/1022 [==============================] - 75s 73ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6932 - val_accuracy: 0.5006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"QCGLTSM1.h5\")"
      ],
      "metadata": {
        "id": "4rY-x3szjOu-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conv1d"
      ],
      "metadata": {
        "id": "Wem1siB7kwro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets parameters for produced model\n",
        "epochs = 10\n",
        "\n",
        "# Strategy to utilise GPU \n",
        "strategy = tf.distribute.OneDeviceStrategy('/gpu:0')\n",
        "\n",
        "# Model compilation using GPU\n",
        "with strategy.scope():\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(sequence_length,1)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(sequence_length, input_shape=(sequence_length, ), activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH3DYGo1KVjR",
        "outputId": "fc580f5c-d4f1-4403-b1a3-9b782f48c7b9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 254, 128)          512       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32512)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               8323328   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,324,097\n",
            "Trainable params: 8,324,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "# Train the model with the x/y train data and validate using the test data after each epoch\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SMzeGBfKXDu",
        "outputId": "ff2352e2-81c9-44b5-c825-2db35d93ed0c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1022/1022 [==============================] - 35s 29ms/step - loss: 0.6988 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.4991\n",
            "Epoch 2/10\n",
            "1022/1022 [==============================] - 7s 7ms/step - loss: 0.6929 - accuracy: 0.5101 - val_loss: 0.6933 - val_accuracy: 0.4976\n",
            "Epoch 3/10\n",
            "1022/1022 [==============================] - 7s 7ms/step - loss: 0.6923 - accuracy: 0.5155 - val_loss: 0.6941 - val_accuracy: 0.4983\n",
            "Epoch 4/10\n",
            "1022/1022 [==============================] - 8s 7ms/step - loss: 0.6908 - accuracy: 0.5240 - val_loss: 0.6942 - val_accuracy: 0.5034\n",
            "Epoch 5/10\n",
            "1022/1022 [==============================] - 7s 7ms/step - loss: 0.6873 - accuracy: 0.5399 - val_loss: 0.6960 - val_accuracy: 0.5022\n",
            "Epoch 6/10\n",
            "1022/1022 [==============================] - 7s 7ms/step - loss: 0.6756 - accuracy: 0.5729 - val_loss: 0.7053 - val_accuracy: 0.5040\n",
            "Epoch 7/10\n",
            "1022/1022 [==============================] - 7s 7ms/step - loss: 0.6376 - accuracy: 0.6327 - val_loss: 0.7391 - val_accuracy: 0.5017\n",
            "Epoch 8/10\n",
            "1022/1022 [==============================] - 7s 7ms/step - loss: 0.5736 - accuracy: 0.6966 - val_loss: 0.7905 - val_accuracy: 0.5059\n",
            "Epoch 9/10\n",
            "1022/1022 [==============================] - 7s 7ms/step - loss: 0.5029 - accuracy: 0.7526 - val_loss: 0.8963 - val_accuracy: 0.5041\n",
            "Epoch 10/10\n",
            "1022/1022 [==============================] - 7s 7ms/step - loss: 0.4402 - accuracy: 0.7939 - val_loss: 0.9955 - val_accuracy: 0.5026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"QCGConv1D1.h5\")"
      ],
      "metadata": {
        "id": "j065BFzikzJ5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conv1d + Normalisation + Dropout"
      ],
      "metadata": {
        "id": "Bwycjmcelhbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets parameters for produced model\n",
        "epochs = 10\n",
        "\n",
        "# Strategy to utilise GPU \n",
        "strategy = tf.distribute.OneDeviceStrategy('/gpu:0')\n",
        "\n",
        "# Model compilation using GPU\n",
        "with strategy.scope():\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(sequence_length,1)))\n",
        "  model.add(Flatten())\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(rate=0.1))\n",
        "  model.add(Dense(sequence_length, input_shape=(sequence_length, ), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1R2nd8dGSad",
        "outputId": "9fe2685e-e3ce-4c0a-d029-5c299313b31b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_1 (Conv1D)           (None, 254, 128)          512       \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 32512)             0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 32512)            130048    \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32512)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               8323328   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,455,169\n",
            "Trainable params: 8,389,633\n",
            "Non-trainable params: 65,536\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "# Train the model with the x/y train data and validate using the test data after each epoch\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgJ6VtsUqjcz",
        "outputId": "ceedb117-0b9e-4d03-abce-a4793100ea28"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1022/1022 [==============================] - 34s 31ms/step - loss: 0.7638 - accuracy: 0.4990 - val_loss: 0.6961 - val_accuracy: 0.5031\n",
            "Epoch 2/10\n",
            "1022/1022 [==============================] - 10s 10ms/step - loss: 0.6900 - accuracy: 0.5352 - val_loss: 0.6999 - val_accuracy: 0.5027\n",
            "Epoch 3/10\n",
            "1022/1022 [==============================] - 11s 10ms/step - loss: 0.6828 - accuracy: 0.5578 - val_loss: 0.7047 - val_accuracy: 0.4993\n",
            "Epoch 4/10\n",
            "1022/1022 [==============================] - 11s 10ms/step - loss: 0.6684 - accuracy: 0.5900 - val_loss: 0.7207 - val_accuracy: 0.4988\n",
            "Epoch 5/10\n",
            "1022/1022 [==============================] - 10s 10ms/step - loss: 0.6458 - accuracy: 0.6251 - val_loss: 0.7275 - val_accuracy: 0.5008\n",
            "Epoch 6/10\n",
            "1022/1022 [==============================] - 10s 10ms/step - loss: 0.6135 - accuracy: 0.6626 - val_loss: 0.7653 - val_accuracy: 0.4997\n",
            "Epoch 7/10\n",
            "1022/1022 [==============================] - 10s 10ms/step - loss: 0.5660 - accuracy: 0.7070 - val_loss: 0.8735 - val_accuracy: 0.5028\n",
            "Epoch 8/10\n",
            "1022/1022 [==============================] - 10s 10ms/step - loss: 0.5056 - accuracy: 0.7530 - val_loss: 0.8438 - val_accuracy: 0.5024\n",
            "Epoch 9/10\n",
            "1022/1022 [==============================] - 10s 10ms/step - loss: 0.4443 - accuracy: 0.7941 - val_loss: 0.9958 - val_accuracy: 0.5047\n",
            "Epoch 10/10\n",
            "1022/1022 [==============================] - 11s 10ms/step - loss: 0.3821 - accuracy: 0.8301 - val_loss: 1.1187 - val_accuracy: 0.5004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training with additioanl data blocks"
      ],
      "metadata": {
        "id": "4OX1PQcM3Esa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "# Train the model with the x/y train data and validate using the test data after each epoch\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt4W7dA1GmWv",
        "outputId": "c870676e-b3e7-4a6b-b025-c4691f83eefc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6142/6142 [==============================] - 195s 31ms/step - loss: 0.7049 - accuracy: 0.5001 - val_loss: 0.6948 - val_accuracy: 0.5003\n",
            "Epoch 2/10\n",
            "6142/6142 [==============================] - 60s 10ms/step - loss: 0.6944 - accuracy: 0.5015 - val_loss: 0.6941 - val_accuracy: 0.5031\n",
            "Epoch 3/10\n",
            "6142/6142 [==============================] - 60s 10ms/step - loss: 0.6934 - accuracy: 0.5015 - val_loss: 0.6933 - val_accuracy: 0.4989\n",
            "Epoch 4/10\n",
            "6142/6142 [==============================] - 61s 10ms/step - loss: 0.6932 - accuracy: 0.5031 - val_loss: 0.6933 - val_accuracy: 0.5013\n",
            "Epoch 5/10\n",
            "6142/6142 [==============================] - 61s 10ms/step - loss: 0.6931 - accuracy: 0.5040 - val_loss: 0.6932 - val_accuracy: 0.4995\n",
            "Epoch 6/10\n",
            "6142/6142 [==============================] - 61s 10ms/step - loss: 0.6931 - accuracy: 0.5058 - val_loss: 0.6933 - val_accuracy: 0.4992\n",
            "Epoch 7/10\n",
            "6142/6142 [==============================] - 61s 10ms/step - loss: 0.6930 - accuracy: 0.5079 - val_loss: 0.6933 - val_accuracy: 0.5006\n",
            "Epoch 8/10\n",
            "6142/6142 [==============================] - 60s 10ms/step - loss: 0.6930 - accuracy: 0.5085 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "6142/6142 [==============================] - 60s 10ms/step - loss: 0.6929 - accuracy: 0.5092 - val_loss: 0.6934 - val_accuracy: 0.4991\n",
            "Epoch 10/10\n",
            "6142/6142 [==============================] - 60s 10ms/step - loss: 0.6928 - accuracy: 0.5101 - val_loss: 0.6937 - val_accuracy: 0.4995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"QCGCND1.h5\")"
      ],
      "metadata": {
        "id": "dJ4znEU1llMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenated samples with best model"
      ],
      "metadata": {
        "id": "ftJLh_aNABYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Example for single model\n",
        "\n",
        "# Sets paramemters for generating train/test data\n",
        "num_blocks = 1000\n",
        "sequence_length = 256\n",
        "samplesConcatenated = 2\n",
        "num_samples = (num_blocks-1)*sequence_length-sequence_length*(samplesConcatenated-1)\n",
        "\n",
        "print(\"Number of samples: \", num_samples)\n",
        "\n",
        "# Seed generator\n",
        "seedGenerator(23)\n",
        "# Get stream data \n",
        "streamData = generatorOutput(num_blocks)\n",
        "\n",
        "# Stores output in variable to allow the sample to be featued in both x and y data\n",
        "X_data = []\n",
        "Y_data = []\n",
        "\n",
        "for i in range(0, num_samples):\n",
        "  X_data.append(streamData[i:i+sequence_length*samplesConcatenated])\n",
        "  Y_data.append([streamData[i+sequence_length*samplesConcatenated]])\n",
        "\n",
        "del streamData\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.3, random_state=32)\n",
        "del X_data\n",
        "del Y_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxe88W2EAD_c",
        "outputId": "429ea49b-9360-4794-848b-5c14528d7a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples:  255488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets parameters for produced model\n",
        "epochs = 10\n",
        "\n",
        "# Strategy to utilise GPU \n",
        "strategy = tf.distribute.OneDeviceStrategy('/gpu:0')\n",
        "\n",
        "# Model compilation using GPU\n",
        "with strategy.scope():\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(sequence_length*samplesConcatenated,1)))\n",
        "  model.add(Flatten())\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(rate=0.1))\n",
        "  model.add(Dense(sequence_length, input_shape=(sequence_length, ), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDmot5yEGlot",
        "outputId": "6d1751c5-1bf7-42d6-cfe2-31de71d8d2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_1 (Conv1D)           (None, 510, 128)          512       \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 65280)             0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 65280)            261120    \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 65280)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               16711936  \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,974,849\n",
            "Trainable params: 16,843,777\n",
            "Non-trainable params: 131,072\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "# Train the model with the x/y train data and validate using the test data after each epoch\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aymB4htvGoa-",
        "outputId": "02cffd82-43db-4fd5-92b7-148691ff0312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1789/1789 [==============================] - 177s 93ms/step - loss: 0.7332 - accuracy: 0.5013 - val_loss: 0.6945 - val_accuracy: 0.5004\n",
            "Epoch 2/10\n",
            "1789/1789 [==============================] - 31s 17ms/step - loss: 0.6931 - accuracy: 0.5116 - val_loss: 0.6942 - val_accuracy: 0.4987\n",
            "Epoch 3/10\n",
            "1789/1789 [==============================] - 30s 17ms/step - loss: 0.6922 - accuracy: 0.5155 - val_loss: 0.6979 - val_accuracy: 0.5025\n",
            "Epoch 4/10\n",
            "1789/1789 [==============================] - 32s 18ms/step - loss: 0.6912 - accuracy: 0.5234 - val_loss: 0.6944 - val_accuracy: 0.5007\n",
            "Epoch 5/10\n",
            "1789/1789 [==============================] - 30s 17ms/step - loss: 0.6900 - accuracy: 0.5327 - val_loss: 0.6994 - val_accuracy: 0.5016\n",
            "Epoch 6/10\n",
            "1789/1789 [==============================] - 31s 17ms/step - loss: 0.6841 - accuracy: 0.5506 - val_loss: 0.7006 - val_accuracy: 0.5028\n",
            "Epoch 7/10\n",
            "1789/1789 [==============================] - 30s 17ms/step - loss: 0.6734 - accuracy: 0.5794 - val_loss: 0.7203 - val_accuracy: 0.5011\n",
            "Epoch 8/10\n",
            "1789/1789 [==============================] - 30s 17ms/step - loss: 0.6529 - accuracy: 0.6139 - val_loss: 0.7296 - val_accuracy: 0.4989\n",
            "Epoch 9/10\n",
            "1789/1789 [==============================] - 31s 17ms/step - loss: 0.6212 - accuracy: 0.6534 - val_loss: 0.7588 - val_accuracy: 0.4984\n",
            "Epoch 10/10\n",
            "1789/1789 [==============================] - 30s 17ms/step - loss: 0.5693 - accuracy: 0.7039 - val_loss: 0.8286 - val_accuracy: 0.4987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not recommended due to large size of model\n",
        "model.save(\"QCGCNDConcat1.h5\")"
      ],
      "metadata": {
        "id": "i5CjkaPqNyW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Graphing current model history"
      ],
      "metadata": {
        "id": "m9cleQ5wgWL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Plotting graph\")\n",
        "# Plot training & validation loss values\n",
        "# Plots loss data\n",
        "plt.plot(range(1, epochs+1), history.history['loss'])\n",
        "plt.plot(range(1, epochs+1), history.history['val_loss'])\n",
        "# Plots a label for each axis\n",
        "plt.ylabel('Loss Value')\n",
        "plt.xlabel('Epoch Number')\n",
        "# Plots the title\n",
        "plt.title('Model loss over epochs')\n",
        "# Plots the legend for each loss\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "# Sets grid for plot\n",
        "plt.grid(linestyle='--', alpha=0.4)\n",
        "# Ensures the x-axis only contains integers\n",
        "plt.xticks(range(1, epochs+1))\n",
        "\n",
        "\n",
        "# Displays plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "odz7gUIW3acl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}